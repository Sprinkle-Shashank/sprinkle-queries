{"cells":[{"metadata":{},"outputs":[],"source":"## Readme \n  #### second version of the script. \n   \n    Version = V.1\n##### updates : \n    1. changed the existing flow, implimented new flow into the script.\n       > earlier the api resonse was wrote into a file in the sprinkle instance (vm-storage) and created a csv based on the created file and then  using that csv we were creating the table.\n    2. ","cell_type":"markdown","execution_count":0},{"metadata":{},"outputs":[],"source":"## Installing necessary modules","cell_type":"markdown","execution_count":0},{"metadata":{"trusted":true},"outputs":[],"source":"!pip3 install pyjwt --upgrade","cell_type":"code","execution_count":1},{"metadata":{"trusted":true},"outputs":[],"source":"!pip3 install cryptography --upgrade","cell_type":"code","execution_count":2},{"metadata":{},"outputs":[],"source":"## Importing sprinkle sdk and reading explore id","cell_type":"markdown","execution_count":0},{"metadata":{"trusted":true},"outputs":[],"source":"# importing sprinkle sdk to intract with sprinkle and redshift.\nfrom sprinkleSdk import SprinkleSdk as sp","cell_type":"code","execution_count":3},{"metadata":{"trusted":true},"outputs":[],"source":"# creating an explore object to create a table in the redshift.\ndf = sp.read_explore('87c504b80ea84797864bb143a8765ec2')","cell_type":"code","execution_count":4},{"metadata":{"trusted":true},"outputs":[],"source":"df","cell_type":"code","execution_count":5},{"metadata":{},"outputs":[],"source":"## Importing necessary modules","cell_type":"markdown","execution_count":0},{"metadata":{"trusted":true},"outputs":[],"source":"import os\nimport csv\nimport jwt\nimport gzip\n#import boto3\nimport requests\nimport pandas as pd\nfrom io import StringIO\nimport awswrangler as wr\nfrom IPython.display import display\nfrom datetime import date, datetime, timezone\n\nclass Daily_Download_Counts():\n    \n    def __init__(self):\n        \n        ''' initalizing the values '''\n        \n        #################\n        ## credentials ##\n        #################\n        \n        self.issuer_id      = \"69a6de75-0dc3-47e3-e053-5b8c7c11a4d1\"\n        self.key_id         = \"59W873K3RD\"\n        self.YOUR_VENDOR_ID = 85409565\n\n        # reading the secret key\n        self.generated_private_key = \"-----BEGIN PRIVATE KEY-----\\nMIGTAgEAMBMGByqGSM49AgEGCCqGSM49AwEHBHkwdwIBAQQgPStV4OhfUk46ow6k\\nIa086H1l6rOW70DT0BdtXp/uMP2gCgYIKoZIzj0DAQehRANCAAT1Q0MljT0/NYsb\\nZRLYLB8wq6hO4Lla/9O8vCIFLJPnIJ48DHfuvPks0i+qV1AuCUOMfkgb/FtK/R+B\\nRvU+tw2G\\n-----END PRIVATE KEY-----\"\n                \n        ###############\n        ## variables ##\n        ###############\n\n        self.frequency     = 'DAILY'\n        self.reportSubType = 'SUMMARY'\n        self.reportType    = 'SALES'\n        self.reportDate    = date.today() #'2022-06-20' # date.today()\n        \n        # save path\n        self.base_dir = os.getcwd()\n        \n        self.today_date = date.today()\n        \n    def sign_appstore_token(self):\n        \n        ''' function for generating JWT tocken '''\n        \n        bin_private_key = self.generated_private_key.encode()\n        current_unix = int(datetime.now(tz=timezone.utc).timestamp())\n        token = jwt.encode({\n                \"iss\": self.issuer_id,\n                \"iat\": current_unix,\n                \"exp\": current_unix + 1000, \n                \"aud\": \"appstoreconnect-v1\",\n        }, key= bin_private_key, algorithm= 'ES256', headers= {\n            \"alg\": \"ES256\",\n            \"kid\": self.key_id,\n            \"typ\": \"JWT\"\n        })\n        \n        return token\n\n    \n    def Get_Download_Counts(self,token):\n        \n        url = f\"https://api.appstoreconnect.apple.com/v1/salesReports?filter[frequency]={self.frequency}&filter[reportDate]={self.reportDate}&filter[reportSubType]={self.reportSubType}&filter[reportType]={self.reportType}&filter[vendorNumber]={self.YOUR_VENDOR_ID}\"\n\n        payload={}\n        headers = {\n          'Authorization': f'Bearer {token}'\n        }\n        \n        #print(headers)\n\n        response = requests.request(\"GET\", url, headers=headers, data=payload)\n        # checking the status code \n        print(response.status_code)\n        response_code = response.status_code\n        \n        # if we receive a response with data sucessfully then we procced to convert the response to csv / parquet file.\n        if response_code == 200:\n            \n            # decompressing the response content.\n            result = gzip.decompress(response.content).decode('utf-8')\n            # reading the data from the memory and converting to dataframe.\n            self.df = self.convert_to_DF(result)\n            return display(self.df)\n        \n        else :\n                        \n            return response_code\n            \n    def convert_to_DF(self,result):\n        \n        ''' function to read the response from the api and convert it into a data frame\n            :param  result : decompressed response content from api call.\n            :return df : dataframe object. \n        '''\n        \n        df = pd.read_csv(StringIO(result),sep='\\t')\n        # adding column for total download counts.\n        # df['total_downloads'] = df['Units'].sum()\n        return df\n    \n    \n    def save_to_parquet(self):\n        ''' func to convert dataframe in to parquet file and save it into a defined location.\n            :param  input : dataframe.\n            :return output: parquet file.\n        '''\n        if self.df :\n            self.df.to_parquet(f'{self.base_dir}/{self.today_date}_apple_apps_daily_download_count.parquet', index=False)\n            \n            \n    def parquet_to_S3(file_path, bucket_name, object_name=None):\n        \"\"\"Upload a file to an S3 bucket\n           :param file_path: string, path to the file\n           :param bucket_name: string, name of the S3 bucket\n           :param object_name: string, name for the S3 object (default is file_path)\n           :return: None\n        \"\"\"\n        wr.s3.to_parquet(dataframe=df,path=\"s3://my-bucket/key/my-file.parquet\")\n            \n            \n        \ntry :\n    \n    # instantiating the class object\n    Apps_daily_downloads = Daily_Download_Counts()\n\n    # starter code for running the token generator\n    token = Apps_daily_downloads.sign_appstore_token()\n\n    # fetching the download counts\n    Apps_daily_downloads.Get_Download_Counts(token)\n    \n    Apps_daily_downloads.save_to_parquet()\n\nexcept Exception as e:\n    print(e)\n    ","cell_type":"code","execution_count":1},{"metadata":{"trusted":true},"outputs":[],"source":"######################\n# latest update cell #\n######################\n\nimport os\nimport csv\nimport jwt\nimport gzip\n#import boto3\nimport requests\nimport pandas as pd\nfrom io import StringIO\nfrom IPython.display import display\nfrom datetime import date, datetime, timezone\n\nclass Daily_Download_Counts():\n    \n    def __init__(self):\n        \n        ''' initalizing the values '''\n        \n        #################\n        ## credentials ##\n        #################\n        \n        self.issuer_id      = \"69a6de75-0dc3-47e3-e053-5b8c7c11a4d1\"\n        self.key_id         = \"59W873K3RD\"\n        self.YOUR_VENDOR_ID = 85409565\n\n        # reading the secret key\n        self.generated_private_key = \"-----BEGIN PRIVATE KEY-----\\nMIGTAgEAMBMGByqGSM49AgEGCCqGSM49AwEHBHkwdwIBAQQgPStV4OhfUk46ow6k\\nIa086H1l6rOW70DT0BdtXp/uMP2gCgYIKoZIzj0DAQehRANCAAT1Q0MljT0/NYsb\\nZRLYLB8wq6hO4Lla/9O8vCIFLJPnIJ48DHfuvPks0i+qV1AuCUOMfkgb/FtK/R+B\\nRvU+tw2G\\n-----END PRIVATE KEY-----\"\n                \n        ###############\n        ## variables ##\n        ###############\n\n        self.frequency     = 'DAILY'\n        self.reportSubType = 'SUMMARY'\n        self.reportType    = 'SALES'\n        self.reportDate    = '2022-06-20' # date.today()\n        \n        # save path\n        self.base_dir = os.getcwd()\n        \n        self.today_date = date.today()\n        \n    def sign_appstore_token(self):\n        \n        ''' function for generating JWT tocken '''\n        \n        bin_private_key = self.generated_private_key.encode()\n        current_unix = int(datetime.now(tz=timezone.utc).timestamp())\n        token = jwt.encode({\n                \"iss\": self.issuer_id,\n                \"iat\": current_unix,\n                \"exp\": current_unix + 1000, \n                \"aud\": \"appstoreconnect-v1\",\n        }, key= bin_private_key, algorithm= 'ES256', headers= {\n            \"alg\": \"ES256\",\n            \"kid\": self.key_id,\n            \"typ\": \"JWT\"\n        })\n        \n        return token\n\n    \n    def Get_Download_Counts(self,token):\n        \n        url = f\"https://api.appstoreconnect.apple.com/v1/salesReports?filter[frequency]={self.frequency}&filter[reportDate]={self.reportDate}&filter[reportSubType]={self.reportSubType}&filter[reportType]={self.reportType}&filter[vendorNumber]={self.YOUR_VENDOR_ID}\"\n\n        payload={}\n        headers = {\n          'Authorization': f'Bearer {token}'\n        }\n        \n        #print(headers)\n\n        response = requests.request(\"GET\", url, headers=headers, data=payload)\n        # checking the status code \n        print(response.status_code)\n        response_code = response.status_code\n        \n        # if we receive a response with data sucessfully then we procced to convert the response to csv / parquet file.\n        if response_code == 200:\n            \n            # decompressing the response content.\n            result = gzip.decompress(response.content).decode('utf-8')\n            # reading the data from the memory and converting to dataframe.\n            self.df = self.convert_to_DF(result)\n            #self.df.reset_index(drop=True, inplace=True)\n            print('new_data')\n            display(self.df)\n            return self.df\n        \n        else :\n                        \n            return response_code\n            \n    def convert_to_DF(self,result):\n        \n        ''' function to read the response from the api and convert it into a data frame\n            :param  result : decompressed response content from api call.\n            :return df : dataframe object. \n        '''\n        \n        df = pd.read_csv(StringIO(result),sep='\\t')\n        # adding column for total download counts.\n        # df['total_downloads'] = df['Units'].sum()\n        return df \n    \n    def read_table_data(self):\n        # creating an explore object to create a table in the redshift.\n        self.df1 = sp.read_explore('87c504b80ea84797864bb143a8765ec2')\n        #self.df1.reset_index(drop=True, inplace=True)\n        print(\"old table data\")\n        display(self.df1)\n        return self.df1\n        \n    def mergeDF(self,old_df,new_df):\n        ''' func for merging old table with new table data into the table. '''\n        \n        # merge 2 tables : already existing table and new table.\n        #concat_df = pd.concat([old_df,new_df],axis=1).reset_index(drop = True)\n        concat_df = pd.concat([old_df.reset_index(drop=True),new_df.reset_index(drop=True)])\n        #concat_df = old_df.append(new_df,ignore_index=True)\n        print('concatnated df data')\n        print(concat_df)\n        display(concat_df)\n        return concat_df\n       \n    def insert_to_table(self,concat_DF):\n        \n        # inserting the record into the table.\n        print(\"inserting to table\")\n        sp.create_or_update_table(\"apple_store_daily_download_tbl\",concat_DF)\n\n            \n            \n        \ntry :\n    \n    # instantiating the class object\n    Apps_daily_downloads = Daily_Download_Counts()\n\n    # starter code for running the token generator\n    token = Apps_daily_downloads.sign_appstore_token()\n\n    # fetching the download counts\n    new_data = Apps_daily_downloads.Get_Download_Counts(token)\n    \n    # reading the downloads data existing in the data-warehouse table.\n    old_data = Apps_daily_downloads.read_table_data()\n    \n    # merge new-data-df and old-data-df \n    concat_df = Apps_daily_downloads.mergeDF(old_data,new_data)\n    \n    # insert concatnated data frame into the table.\n    #Apps_daily_downloads.insert_to_table(concat_df)\n\nexcept Exception as e:\n    print(e)\n    ","cell_type":"code","execution_count":17},{"metadata":{},"outputs":[],"source":"## Inspecting downloaded csv","cell_type":"markdown","execution_count":0},{"metadata":{"trusted":true},"outputs":[],"source":"today = date.today()\nprint(str(today)+\"_apple_apps_daily_download_count.csv\")\nnew_df = pd.read_csv(str(today)+\"_apple_apps_daily_download_count.csv\")\ndisplay(new_df)","cell_type":"code","execution_count":8},{"metadata":{"trusted":true},"outputs":[],"source":"new_df.info()","cell_type":"code","execution_count":9},{"metadata":{},"outputs":[],"source":"## Moving the downloads data into warehouse","cell_type":"markdown","execution_count":0},{"metadata":{"trusted":true},"outputs":[],"source":"sp.create_or_update_table(\"apple_store_daily_download_tbl\",new_df)","cell_type":"code","execution_count":11},{"metadata":{},"outputs":[],"source":"","cell_type":"code","execution_count":0}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.10.8","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":2}